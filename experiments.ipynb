{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af99b026-21b8-4d59-8aa5-0b5bfceea6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-03 16:31:47,085 - hy3dgen.shapgen - INFO - Try to load model from local path: /root/.cache/hy3dgen/tencent/Hunyuan3D-2/hunyuan3d-dit-v2-0\n",
      "2025-12-03 16:31:47,085 - hy3dgen.shapgen - INFO - Model path not exists, try to download from huggingface\n",
      "2025-12-03 16:31:47,325 - hy3dgen.shapgen - INFO - Loading model from /root/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/snapshots/9cd649ba6913f7a852e3286bad86bfa9a2d83dcf/hunyuan3d-dit-v2-0/model.fp16.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCrossAttentionEncoder INFO: pc_sharpedge_size is given, using pc_size=5120, pc_sharpedge_size=5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|██████████| 50/50 [00:07<00:00,  6.33it/s]\n",
      "Volume Decoding: 100%|██████████| 7134/7134 [00:50<00:00, 140.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mesh to outputs/demo_karma.glb\n",
      "CPU times: user 1min 22s, sys: 39.1 s, total: 2min 1s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline\n",
    "\n",
    "pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(\n",
    "    'tencent/Hunyuan3D-2',\n",
    "    subfolder='hunyuan3d-dit-v2-0',\n",
    "    use_safetensors=True,\n",
    ")\n",
    "result = pipeline(\n",
    "    image=\"assets/Karma.png\",\n",
    "    num_inference_steps=50,\n",
    ")\n",
    "mesh = result[0]\n",
    "\n",
    "mesh.export(\"outputs/demo_karma.glb\")\n",
    "print(\"Saved mesh to outputs/demo_karma.glb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f002410-432e-4e1c-98d9-97b1109c08ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-03 16:56:11,580 - hy3dgen.shapgen - INFO - Try to load model from local path: /root/.cache/hy3dgen/tencent/Hunyuan3D-2/hunyuan3d-dit-v2-0\n",
      "2025-12-03 16:56:11,580 - hy3dgen.shapgen - INFO - Model path not exists, try to download from huggingface\n",
      "2025-12-03 16:56:11,841 - hy3dgen.shapgen - INFO - Loading model from /root/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/snapshots/9cd649ba6913f7a852e3286bad86bfa9a2d83dcf/hunyuan3d-dit-v2-0/model.fp16.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCrossAttentionEncoder INFO: pc_sharpedge_size is given, using pc_size=5120, pc_sharpedge_size=5120\n",
      "Enable sparse flash in CrossAttentionDecoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|██████████| 50/50 [00:07<00:00,  6.33it/s]\n",
      "Volume Decoding:  47%|████▋     | 3347/7134 [01:13<01:16, 49.78it/s]"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline\n",
    "\n",
    "pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(\n",
    "    'tencent/Hunyuan3D-2',\n",
    "    subfolder='hunyuan3d-dit-v2-0',\n",
    "    use_safetensors=True,\n",
    ")\n",
    "pipeline.enable_sparse_flash()\n",
    "result = pipeline(\n",
    "    image=\"assets/Karma.png\",\n",
    "    num_inference_steps=50,\n",
    ")\n",
    "mesh = result[0]\n",
    "\n",
    "mesh.export(\"outputs/demo_karma.glb\")\n",
    "print(\"Saved mesh to outputs/demo_karma.glb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae8bfc2-8e38-41b9-9cab-b885264c63af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  67%|██████▋   | 4/6 [00:00<00:00,  9.60it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 12.87it/s]\n",
      "Loading pipeline components...:  67%|██████▋   | 4/6 [00:06<00:03,  1.53s/it]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/snapshots/9cd649ba6913f7a852e3286bad86bfa9a2d83dcf/hunyuan3d-paint-v2-0-turbo/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/snapshots/9cd649ba6913f7a852e3286bad86bfa9a2d83dcf/hunyuan3d-paint-v2-0-turbo/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:06<00:00,  1.07s/it]\n",
      "Expected types for unet: (<class 'diffusers_modules.local.unet.modules.UNet2p5DConditionModel'>,), got <class 'diffusers_modules.local.modules.UNet2p5DConditionModel'>.\n",
      "/root/.cache/huggingface/modules/diffusers_modules/local/pipeline.py:598: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  index = torch.range(29, 0, -bsz, device='cuda').long()\n",
      "The first timestep on the custom timestep schedule is 989, not `self.config.num_train_timesteps - 1`: 999. You may get unexpected results when using this timestep schedule.\n",
      "The custom timestep schedule contains the following timesteps which are not on the original training/distillation timestep schedule: [tensor(890), tensor(791), tensor(692), tensor(593), tensor(494), tensor(395), tensor(296), tensor(197), tensor(98)]. You may get unexpected results when using this timestep schedule.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved textured mesh to outputs/demo_textured_karma.glb\n"
     ]
    }
   ],
   "source": [
    "from hy3dgen.texgen import Hunyuan3DPaintPipeline\n",
    "# 2. Texture\n",
    "tex_pipe = Hunyuan3DPaintPipeline.from_pretrained(\"tencent/Hunyuan3D-2\")\n",
    "textured_mesh = tex_pipe(mesh, image=\"assets/Karma.png\")\n",
    "\n",
    "textured_mesh.export(\"outputs/demo_textured_karma.glb\")\n",
    "print(\"Saved textured mesh to outputs/demo_textured_karma.glb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2264af6a-565c-47cc-a6d6-5a5a28a30fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Hunyuan3D-2/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27236b8d-081e-440c-96b4-5f67cf423cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:\n",
      "Unable to load the following plugins:\n",
      "\n",
      "\tlibfilter_ao.so: libfilter_ao.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libfilter_ao.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibfilter_meshing.so: libfilter_meshing.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libfilter_meshing.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibfilter_plymc.so: libfilter_plymc.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libfilter_plymc.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibfilter_sample_gpu.so: libfilter_sample_gpu.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libfilter_sample_gpu.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibfilter_sdfgpu.so: libfilter_sdfgpu.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libfilter_sdfgpu.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibfilter_ssynth.so: libfilter_ssynth.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libfilter_ssynth.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibfilter_texture_defragmentation.so: libfilter_texture_defragmentation.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libfilter_texture_defragmentation.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibio_base.so: libio_base.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libio_base.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\tlibio_x3d.so: libio_x3d.so does not seem to be a Qt Plugin.\n",
      "\n",
      "Cannot load library /workspace/Hunyuan3D-2/.venv/lib/python3.10/site-packages/pymeshlab/lib/plugins/libio_x3d.so: (libOpenGL.so.0: cannot open shared object file: No such file or directory)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 17:48:17,194 - hy3dgen.shapgen - INFO - Try to load model from local path: /root/.cache/hy3dgen/tencent/Hunyuan3D-2/hunyuan3d-dit-v2-0\n",
      "2025-11-27 17:48:17,195 - hy3dgen.shapgen - INFO - Model path not exists, try to download from huggingface\n",
      "2025-11-27 17:48:17,449 - hy3dgen.shapgen - INFO - Loading model from /root/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/snapshots/9cd649ba6913f7a852e3286bad86bfa9a2d83dcf/hunyuan3d-dit-v2-0/model.fp16.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCrossAttentionEncoder INFO: pc_sharpedge_size is given, using pc_size=5120, pc_sharpedge_size=5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|██████████| 50/50 [00:08<00:00,  6.25it/s]\n",
      "Volume Decoding: 100%|██████████| 7134/7134 [00:16<00:00, 444.68it/s]\n",
      "Loading pipeline components...:  17%|█▋        | 1/6 [00:00<00:01,  3.63it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  7.87it/s]\n",
      "Loading pipeline components...:  67%|██████▋   | 4/6 [00:05<00:03,  1.64s/it]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/snapshots/9cd649ba6913f7a852e3286bad86bfa9a2d83dcf/hunyuan3d-paint-v2-0-turbo/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/snapshots/9cd649ba6913f7a852e3286bad86bfa9a2d83dcf/hunyuan3d-paint-v2-0-turbo/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "Expected types for unet: (<class 'diffusers_modules.local.unet.modules.UNet2p5DConditionModel'>,), got <class 'diffusers_modules.local.modules.UNet2p5DConditionModel'>.\n",
      "/root/.cache/huggingface/modules/diffusers_modules/local/pipeline.py:598: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  index = torch.range(29, 0, -bsz, device='cuda').long()\n",
      "The first timestep on the custom timestep schedule is 989, not `self.config.num_train_timesteps - 1`: 999. You may get unexpected results when using this timestep schedule.\n",
      "The custom timestep schedule contains the following timesteps which are not on the original training/distillation timestep schedule: [tensor(890), tensor(791), tensor(692), tensor(593), tensor(494), tensor(395), tensor(296), tensor(197), tensor(98)]. You may get unexpected results when using this timestep schedule.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved textured mesh to outputs/demo_textured_karma.glb\n"
     ]
    }
   ],
   "source": [
    "from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline\n",
    "from hy3dgen.texgen import Hunyuan3DPaintPipeline\n",
    "\n",
    "\n",
    "shape_pipe = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(\"tencent/Hunyuan3D-2\")\n",
    "mesh = shape_pipe(image=\"assets/Karma.png\")[0]\n",
    "\n",
    "# 2. Texture\n",
    "tex_pipe = Hunyuan3DPaintPipeline.from_pretrained(\"tencent/Hunyuan3D-2\")\n",
    "textured_mesh = tex_pipe(mesh, image=\"assets/Karma.png\")\n",
    "\n",
    "textured_mesh.export(\"outputs/demo_textured_karma.glb\")\n",
    "print(\"Saved textured mesh to outputs/demo_textured_karma.glb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f492c-fd7e-4ded-95c6-20ac92f42fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
